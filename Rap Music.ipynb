{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rap Music Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install webdriver-manager\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 88.0.4324\n",
      "[WDM] - Get LATEST driver version for 88.0.4324\n",
      "[WDM] - Driver [/Users/sarahamiraslani/.wdm/drivers/chromedriver/mac64/88.0.4324.96/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "# Using Chrome to acess web\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "# Open the website\n",
    "driver.get(\"https://genius.com/#top-songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of ways to tell our webdriver what elements to find, all of which use selectors. A selector is a unique idetnfier for an element on a webpage. To find the selector for a specific element, we need to inspect the webpage. Doing so wil show use the HTML underlying any webpage. \n",
    "\n",
    "Xpath is the language used for locating nodes in an XML document. One of the main reasons for using Xpath is when you don't have a suitable id or name attribute for the element you wish to locate. You can use XPath to either locate the element in absolute terms (not advised), or relative to an element that does have an id or name attribute. XPath locators can also be used to specify elements via attributes other than id and name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell webdriver to select Genre as rap\n",
    "rap_button = driver.find_elements_by_xpath('//*[@id=\"top-songs\"]/div/div[2]/div/div/div[2]/div[2]/div[3]/div')[0]\n",
    "rap_button.click()\n",
    "\n",
    "\n",
    "# Scrape songs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #top-songs > div > div.PageGridCenter-q0ues6-0.Charts__LoadMore-sc-1re0f44-1.eDwRUT > div\n",
    "# load_more = driver.find_elements_by_xpath('/html/body/div/div/div[5]/div[2]/div/div[4]')\n",
    "# load_more.click()\n",
    "# #top-songs > div > div.PageGridCenter-q0ues6-0.Charts__LoadMore-sc-1re0f44-1.eDwRUT > div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'WebElement' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-fb0c99e64734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msong\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msongs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'WebElement' object is not iterable"
     ]
    }
   ],
   "source": [
    "songs = driver.find_elements_by_xpath('//*[@id=\"top-songs\"]/div/div[3]')[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for song in songs:\n",
    "#     print(song)\n",
    "\n",
    "# # # songs_list = []\n",
    "\n",
    "# for song in range(len(songs)):\n",
    "#     songs_list.append(songs[song].text)\n",
    "    \n",
    "# songs_list = songs_list[0]\n",
    "\n",
    "# songs_list.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame\n",
    "column_names = ['Title','Artist','Lyrics','Comments']\n",
    "df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import requests\n",
    "\n",
    "def request_artist_info(artist_name, page):\n",
    "    \n",
    "    base_url = 'https://api.genius.com'\n",
    "    token = getpass.getpass('Enter your Genius API token:')\n",
    "    \n",
    "    headers = {'Authorization': 'Bearer ' + token}\n",
    "    search_url = base_url + '/search?per_page=50&page=' + str(page)\n",
    "    data = {'q': artist_name}\n",
    "    response = requests.get(search_url, data=data, headers=headers)\n",
    "    \n",
    "    return response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "response = request_artist_info('Drake', 1)\n",
    "json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = []\n",
    "song_name = []\n",
    "pageviews = []\n",
    "\n",
    "for hit in json['response']['hits']: \n",
    "    artist.append(hit['result']['primary_artist']['name'])\n",
    "    song_name.append(hit['result']['title'])\n",
    "    pageviews.append(hit['result']['stats']['pageviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title']= song_name\n",
    "df['Artist'] = artist\n",
    "df['pageviews'] = pageviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_song_url(artist_name, song_cap):\n",
    "\n",
    "    page = 1\n",
    "    songs = []\n",
    "    \n",
    "    while True:\n",
    "        response = request_artist_info(artist_name, page)\n",
    "        json = response.json()       \n",
    "        song_info = []\n",
    "        \n",
    "        for hit in json['response']['hits']:\n",
    "            if artist_name.lower() in hit['result']['primary_artist']['name'].lower():\n",
    "                song_info.append(hit)\n",
    "        \n",
    "        for song in song_info:\n",
    "            if (len(songs) < song_cap):\n",
    "                url = song['result']['url']\n",
    "                songs.append(url)\n",
    "            \n",
    "        if (len(songs) == song_cap):\n",
    "            break\n",
    "        else:\n",
    "            page += 1\n",
    "    \n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = request_song_url('drake',20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for url in urls: \n",
    "    \n",
    "    req = Request(url, headers = {\"User-Agent\" : \"Mozilla/5.0\"})\n",
    "    webpage = urlopen(req).read()\n",
    "\n",
    "    # Create a BeautifulSoup object \n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    html = soup.prettify('utf-8')\n",
    "    songs = {}\n",
    "    songs['lyrics'] = [];\n",
    "    songs['comments'] = [];\n",
    "\n",
    "    # Extract user comments on the song\n",
    "    for div in soup.findAll('div',attrs={'class':'rich_text_formatting'}):\n",
    "        comments = div.text.strip().split(\"\\n\")\n",
    "        \n",
    "        for comment in comments: \n",
    "            if comment != \"\":\n",
    "                songs['comments'].append(comment);\n",
    "                df['Comments'].iloc[counter] = songs['comments']\n",
    "        \n",
    "    # Extract the lyrics of the song\n",
    "    for div in soup.findAll('div', attrs = {'class':'lyrics'}):\n",
    "        songs['lyrics'].append(div.text.strip().split(\"\\n\"));\n",
    "        df['Lyrics'].iloc[counter] = songs['lyrics'][0]\n",
    "    \n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean_lyrics(lst):\n",
    "    \n",
    "    new_lst = []\n",
    "    for i in lst:\n",
    "        if '['in i: \n",
    "            continue\n",
    "        else: \n",
    "            new_lst.append(i)\n",
    "    \n",
    "    my_string = ' '.join(new_lst)\n",
    "    new_str = my_string.translate(str.maketrans('','', string.punctuation))\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Lyrics'] = df['Lyrics'].apply(clean_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments(lst):\n",
    "    my_string = ' '.join(lst)\n",
    "    new_str = my_string.translate(str.maketrans('', '', string.punctuation))\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Comments'] = df['Comments'].apply(clean_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the language library\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def get_lemmas(string):\n",
    "\n",
    "    # Create a document object\n",
    "    doc = nlp(string)\n",
    "\n",
    "    lemmas = []\n",
    "\n",
    "    for token in doc: \n",
    "        if token.pos == 103: # takes care of spaces\n",
    "            continue\n",
    "        elif token.lemma_ == '-PRON-':\n",
    "            lemmas.append(token)\n",
    "        else: \n",
    "            lemmas.append(token.lemma_)\n",
    "            \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyric_lemmas'] = df['Lyrics'].apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "df['comments_scores'] = df['Comments'].apply(lambda comment: sid.polarity_scores(comment))\n",
    "df['lyrics_scores'] = df['Lyrics'].apply(lambda lyric: sid.polarity_scores(lyric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comments_compound'] = df['comments_scores'].apply(lambda d:d['compound'])\n",
    "df['lyrics_compound'] = df['lyrics_scores'].apply(lambda d:d['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['lyrics_compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df['Title'],df['pageviews'])\n",
    "plt.ylabel('Page Views')\n",
    "plt.title('Genius Page Views by Song')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
